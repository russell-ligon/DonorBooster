{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T03:27:11.021428Z",
     "start_time": "2020-11-16T03:27:11.016410Z"
    }
   },
   "outputs": [],
   "source": [
    "#%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T03:27:12.914197Z",
     "start_time": "2020-11-16T03:27:11.873061Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T03:27:13.731852Z",
     "start_time": "2020-11-16T03:27:13.716698Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T03:27:14.482949Z",
     "start_time": "2020-11-16T03:27:14.475443Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, date #for time duration calculations\n",
    "from dateutil.parser import parse #for fuzzy finding year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T03:27:15.293811Z",
     "start_time": "2020-11-16T03:27:15.263267Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle #for saving output files, pickles\n",
    "from sys import stdout\n",
    "import time #for time.sleep function to delay calls\n",
    "from tqdm import tqdm #for updating loop\n",
    "#from os import listdir\n",
    "#from os.path import isfile, join\n",
    "import glob #pattern matching and expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Python packages - you may have to pip install sqlalchemy, sqlalchemy_utils, and psycopg2.\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "from sqlalchemy.sql import table, column, select, update, insert\n",
    "import psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#In Python: Define your username and password used above. I've defined the database name (we're \n",
    "#using a dataset on births, so I call it birth_db). \n",
    "dbname = 'donors_db'\n",
    "username = 'xxxx' #Enter username here\n",
    "pswd = 'xxxx' #enter system password here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 'engine' is a connection to a database\n",
    "## Here, we're using postgres, but sqlalchemy can connect to other things too.\n",
    "engine = create_engine('postgresql://%s:%s@localhost/%s'%(username,pswd,dbname))\n",
    "print('postgresql://%s:%s@localhost/%s'%(username,pswd,dbname))\n",
    "print(engine.url)\n",
    "# Replace localhost with IP address if accessing a remote server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a database (if it doesn't exist)\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "print(database_exists(engine.url))\n",
    "print(engine.url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This block reads in archival data (from the web.archive.org) and old data from (an Insight Fellow proj on AWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### data from: https://web.archive.org/web/20121019202946/http://developer.donorschoose.org/the-data\n",
    "#### Look at the first few rows of the CSV file\n",
    "arch_data = pd.read_csv(\"/home/russell/Documents/DataScience/DonorsChoose/Data/donorschoose-org-1may2011-v1-projects.csv\")\n",
    "\n",
    "######drop 'active' projects\n",
    "\n",
    "orig_rowlen=len(arch_data.index)\n",
    "\n",
    "arch_data = arch_data[arch_data.funding_status != 'live']\n",
    "\n",
    "new_rowlen=len(arch_data.index)\n",
    "\n",
    "print(\"***Web Archive Data\")\n",
    "\n",
    "print(\"original rows =\"+str(orig_rowlen)+\", new rows =\"+str(new_rowlen))\n",
    "\n",
    "#### data from https://github.com/adilmoujahid/DonorsChoose_Visualization/issues/10\n",
    "old_df = pd.read_csv(\"/home/russell/Downloads/opendata_projects.csv\", thousands = ',')\n",
    "\n",
    "######drop 'active' projects\n",
    "\n",
    "old_rowlen=len(old_df.index)\n",
    "\n",
    "old_df = old_df[old_df.funding_status != 'live']\n",
    "\n",
    "new_oldrowlen=len(old_df.index)\n",
    "\n",
    "print(\"****Github Data\")\n",
    "\n",
    "print(\"original rows =\"+str(old_rowlen)+\", new rows =\"+str(new_oldrowlen))\n",
    "\n",
    "#get shared column names, keeping order\n",
    "\n",
    "keepcolumns=set(old_df.columns).intersection(arch_data.columns)\n",
    "\n",
    "A=old_df.columns.values.tolist()\n",
    "\n",
    "keepcolumns=sorted(keepcolumns, key=A.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(old_df.columns).difference(arch_data.columns) #columns not shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "## keep only shared columns, then combine\n",
    "\n",
    "arch_data = arch_data[keepcolumns]\n",
    "\n",
    "old_df = old_df[keepcolumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigold = arch_data.append(old_df) # combine\n",
    "\n",
    "bigold['calendar_completed']=bigold.date_completed.str.split(' ').str[0]\n",
    "bigold['year_completed']=bigold.calendar_completed.str.split('-').str[0]\n",
    "bigold['calendar_expired']=bigold.date_expiration.str.split(' ').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigold['school_latitude'] = bigold.school_latitude.astype(float)\n",
    "\n",
    "bigold['school_longitude'] =bigold.school_longitude.astype(float)\n",
    "\n",
    "####replace nas for these two columns with 0, required for conversion to int\n",
    "values = {'year_completed':0,'num_donors':0}\n",
    "\n",
    "bigold = bigold.fillna(value=values)\n",
    "\n",
    "bigold['year_completed']=bigold.year_completed.astype(int)\n",
    "\n",
    "bigold['num_donors']=bigold.num_donors.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T03:26:55.205203Z",
     "start_time": "2020-11-16T03:26:55.089670Z"
    }
   },
   "outputs": [],
   "source": [
    "#have composite df now (bigold), so clean up old_df and arch_data\n",
    "del old_df;del arch_data\n",
    "\n",
    "print(bigold.shape)\n",
    "\n",
    "bigold.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bigold['funding_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert archival into database from python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### insert data into database from Python\n",
    "bigold.to_sql('hist_projects', engine, if_exists='replace',chunksize=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data scraped from DC and saved in pickle format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all pickle files from folder into a list, 'picks'\n",
    "\n",
    "picks = sorted(glob.glob(\"/home/russell/Documents/DataScience/DonorsChoose/Data/Metrics/*pickle\")) \n",
    "picks=picks[0:3]\n",
    "print(len(picks))\n",
    "\n",
    "\n",
    "#this will create a master list with the same # of elements as projects\n",
    "basic_list = []\n",
    "\n",
    "for pf in picks:\n",
    "    #https://stackoverflow.com/a/3249684/1602288\n",
    "    stdout.write(\"\\r%s\" % pf)\n",
    "    stdout.flush()\n",
    "    check=pickle.load(open(pf,\"rb\"))\n",
    "    #check=check[['id','proposalURL']]\n",
    "    if (isinstance(check, pd.DataFrame)) and (len(check.index)>0):\n",
    "        basic_list.append(check)\n",
    "    #basic_list.append(check)\n",
    "    \n",
    "    \n",
    "    #basic_list.append(pickle.load(open(pf,\"rb\")))\n",
    "    #basic_list = basic_list+(pickle.load(open(picks[0],\"rb\")))\n",
    "    #sleep(.4)\n",
    "stdout.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigframe = pd.concat(basic_list)\n",
    "#schoolTypes, teacherTypes #these variables are 'dictionaries' and need to be dealt with\n",
    "\n",
    "bigframe=bigframe.drop(['schoolTypes', 'teacherTypes'], axis=1)\n",
    "\n",
    "bigframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/a/40121869/1602288\n",
    "ffd = bigframe['fullyFundedDate'].values.tolist()\n",
    "\n",
    "years=[]\n",
    "\n",
    "for date in ffd:\n",
    "    try:\n",
    "        years.append(parse(str(date), fuzzy=True).year)\n",
    "    except:   \n",
    "        years.append(np.nan)\n",
    "\n",
    "bigframe['ffyear']=years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nybig: 'latitude','longitude','ffyear'\n",
    "\n",
    "bigframe['latitude']=bigframe.latitude.astype(float)\n",
    "\n",
    "bigframe['longitude']=bigframe.longitude.astype(float)\n",
    "\n",
    "####replace nas for these two columns with 0, required for conversion to int\n",
    "values = {'ffyear':0,'numDonors':0}\n",
    "bigframe = bigframe.fillna(value=values)\n",
    "\n",
    "bigframe['ffyear']=bigframe.ffyear.astype(int)\n",
    "\n",
    "bigframe['numDonors']=bigframe.numDonors.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigframe['expirationTime'] = bigframe['expirationTime'].apply(str)\n",
    "bigframe['expirationTime']=bigframe['expirationTime'].str[1:-5]\n",
    "bigframe['timeback']=pd.to_numeric(bigframe['expirationTime'])\n",
    "bigframe['right_date']=pd.to_datetime(bigframe['expirationDate'],format='%Y-%m-%d')\n",
    "bigframe['start_date'] = bigframe.apply(lambda row: row['right_date'] - timedelta(seconds=row['timeback']),axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "bigframe.head(3)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert scraped data into database from python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T03:35:28.538635Z",
     "start_time": "2020-11-16T03:35:28.464167Z"
    }
   },
   "outputs": [],
   "source": [
    "# insert data into database from Python\n",
    "bigframe.to_sql('scraped_project_metrics', engine, if_exists='append',chunksize=100000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
