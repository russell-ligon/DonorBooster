{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, date #for time duration calculations\n",
    "from dateutil.parser import parse #for fuzzy finding year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle #for saving output files, pickles\n",
    "from sys import stdout\n",
    "import time #for time.sleep function to delay calls\n",
    "from tqdm import tqdm #for updating loop\n",
    "#from os import listdir\n",
    "#from os.path import isfile, join\n",
    "import glob #pattern matching and expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Python packages - you may have to pip install sqlalchemy, sqlalchemy_utils, and psycopg2.\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "from sqlalchemy.sql import table, column, select, update, insert\n",
    "import psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#In Python: Define your username and password used above. I've defined the database name (we're \n",
    "#using a dataset on births, so I call it birth_db). \n",
    "dbname = 'donors_db'\n",
    "username = 'russell'\n",
    "pswd = 'bradypodion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://russell:bradypodion@localhost/donors_db\n",
      "postgresql://russell:bradypodion@localhost/donors_db\n"
     ]
    }
   ],
   "source": [
    "## 'engine' is a connection to a database\n",
    "## Here, we're using postgres, but sqlalchemy can connect to other things too.\n",
    "engine = create_engine('postgresql://%s:%s@localhost/%s'%(username,pswd,dbname))\n",
    "print('postgresql://%s:%s@localhost/%s'%(username,pswd,dbname))\n",
    "print(engine.url)\n",
    "# Replace localhost with IP address if accessing a remote server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "postgresql://russell:bradypodion@localhost/donors_db\n"
     ]
    }
   ],
   "source": [
    "## create a database (if it doesn't exist)\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "print(database_exists(engine.url))\n",
    "print(engine.url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This block reads in archival data (from the web.archive.org) and old data from (an Insight Fellow proj on AWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Web Archive Data\n",
      "original rows =304707, new rows =285382\n",
      "****Github Data\n",
      "original rows =1203287, new rows =1139787\n"
     ]
    }
   ],
   "source": [
    "#### data from: https://web.archive.org/web/20121019202946/http://developer.donorschoose.org/the-data\n",
    "#### Look at the first few rows of the CSV file\n",
    "arch_data = pd.read_csv(\"/home/russell/Documents/DataScience/DonorsChoose/Data/donorschoose-org-1may2011-v1-projects.csv\")\n",
    "\n",
    "######drop 'active' projects\n",
    "\n",
    "orig_rowlen=len(arch_data.index)\n",
    "\n",
    "arch_data = arch_data[arch_data.funding_status != 'live']\n",
    "\n",
    "new_rowlen=len(arch_data.index)\n",
    "\n",
    "print(\"***Web Archive Data\")\n",
    "\n",
    "print(\"original rows =\"+str(orig_rowlen)+\", new rows =\"+str(new_rowlen))\n",
    "\n",
    "#### data from https://github.com/adilmoujahid/DonorsChoose_Visualization/issues/10\n",
    "old_df = pd.read_csv(\"/home/russell/Downloads/opendata_projects.csv\", thousands = ',')\n",
    "\n",
    "######drop 'active' projects\n",
    "\n",
    "old_rowlen=len(old_df.index)\n",
    "\n",
    "old_df = old_df[old_df.funding_status != 'live']\n",
    "\n",
    "new_oldrowlen=len(old_df.index)\n",
    "\n",
    "print(\"****Github Data\")\n",
    "\n",
    "print(\"original rows =\"+str(old_rowlen)+\", new rows =\"+str(new_oldrowlen))\n",
    "\n",
    "#get shared column names, keeping order\n",
    "\n",
    "keepcolumns=set(old_df.columns).intersection(arch_data.columns)\n",
    "\n",
    "A=old_df.columns.values.tolist()\n",
    "\n",
    "keepcolumns=sorted(keepcolumns, key=A.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' \"teacher_ny_teaching_fellow\"'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(old_df.columns).difference(arch_data.columns) #columns not shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "## keep only shared columns, then combine\n",
    "\n",
    "arch_data = arch_data[keepcolumns]\n",
    "\n",
    "old_df = old_df[keepcolumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigold = arch_data.append(old_df) # combine\n",
    "\n",
    "bigold['calendar_completed']=bigold.date_completed.str.split(' ').str[0]\n",
    "\n",
    "bigold['year_completed']=bigold.calendar_completed.str.split('-').str[0]\n",
    "\n",
    "bigold['calendar_expired']=bigold.date_expiration.str.split(' ').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigold['school_latitude'] = bigold.school_latitude.astype(float)\n",
    "\n",
    "bigold['school_longitude'] =bigold.school_longitude.astype(float)\n",
    "\n",
    "####replace nas for these two columns with 0, required for conversion to int\n",
    "values = {'year_completed':0,'num_donors':0}\n",
    "\n",
    "bigold = bigold.fillna(value=values)\n",
    "\n",
    "bigold['year_completed']=bigold.year_completed.astype(int)\n",
    "\n",
    "bigold['num_donors']=bigold.num_donors.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1425169, 46)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_projectid</th>\n",
       "      <th>_teacher_acctid</th>\n",
       "      <th>_schoolid</th>\n",
       "      <th>school_ncesid</th>\n",
       "      <th>school_latitude</th>\n",
       "      <th>school_longitude</th>\n",
       "      <th>school_city</th>\n",
       "      <th>school_state</th>\n",
       "      <th>school_zip</th>\n",
       "      <th>school_metro</th>\n",
       "      <th>school_district</th>\n",
       "      <th>school_county</th>\n",
       "      <th>school_charter</th>\n",
       "      <th>school_magnet</th>\n",
       "      <th>school_year_round</th>\n",
       "      <th>school_nlns</th>\n",
       "      <th>school_kipp</th>\n",
       "      <th>school_charter_ready_promise</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>teacher_teach_for_america</th>\n",
       "      <th>primary_focus_subject</th>\n",
       "      <th>primary_focus_area</th>\n",
       "      <th>secondary_focus_subject</th>\n",
       "      <th>secondary_focus_area</th>\n",
       "      <th>resource_type</th>\n",
       "      <th>poverty_level</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>vendor_shipping_charges</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>payment_processing_charges</th>\n",
       "      <th>fulfillment_labor_materials</th>\n",
       "      <th>total_price_excluding_optional_support</th>\n",
       "      <th>total_price_including_optional_support</th>\n",
       "      <th>students_reached</th>\n",
       "      <th>total_donations</th>\n",
       "      <th>num_donors</th>\n",
       "      <th>eligible_double_your_impact_match</th>\n",
       "      <th>eligible_almost_home_match</th>\n",
       "      <th>funding_status</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>date_completed</th>\n",
       "      <th>date_thank_you_packet_mailed</th>\n",
       "      <th>date_expiration</th>\n",
       "      <th>calendar_completed</th>\n",
       "      <th>year_completed</th>\n",
       "      <th>calendar_expired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>06dd1b6687a1cc9c3b6d005f0e678228</td>\n",
       "      <td>ec1afc0b1a77a3603718dcd1ca484106</td>\n",
       "      <td>26e476f93a7b248da90b883b8d45f3ff</td>\n",
       "      <td>1.812810e+11</td>\n",
       "      <td>39.816110</td>\n",
       "      <td>-86.283113</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>IN</td>\n",
       "      <td>46214.0</td>\n",
       "      <td>urban</td>\n",
       "      <td>Msd Of Wayne Twp</td>\n",
       "      <td>Marion</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>False</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Books</td>\n",
       "      <td>high</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.50</td>\n",
       "      <td>35.0</td>\n",
       "      <td>813.50</td>\n",
       "      <td>957.06</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>expired</td>\n",
       "      <td>2011-04-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-09-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-09-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>4ff621b7ae38d10d350c207bd454b0a9</td>\n",
       "      <td>db7e23fd42f3d6cfd2aa673e008b73f6</td>\n",
       "      <td>a7cf5b5a11e2586b6deb168d71c763ef</td>\n",
       "      <td>6.339301e+10</td>\n",
       "      <td>36.700132</td>\n",
       "      <td>-121.657760</td>\n",
       "      <td>Salinas</td>\n",
       "      <td>CA</td>\n",
       "      <td>93906.0</td>\n",
       "      <td>urban</td>\n",
       "      <td>Salinas City Elem Sch District</td>\n",
       "      <td>Monterey</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>False</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>Math &amp; Science</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>high</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>3.84</td>\n",
       "      <td>35.14</td>\n",
       "      <td>5.76</td>\n",
       "      <td>35.0</td>\n",
       "      <td>463.78</td>\n",
       "      <td>545.62</td>\n",
       "      <td>23.0</td>\n",
       "      <td>523.92</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>completed</td>\n",
       "      <td>2011-04-29</td>\n",
       "      <td>2011-04-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-09-28</td>\n",
       "      <td>2011-04-30</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011-09-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           _projectid                   _teacher_acctid  \\\n",
       "163  06dd1b6687a1cc9c3b6d005f0e678228  ec1afc0b1a77a3603718dcd1ca484106   \n",
       "185  4ff621b7ae38d10d350c207bd454b0a9  db7e23fd42f3d6cfd2aa673e008b73f6   \n",
       "\n",
       "                            _schoolid  school_ncesid  school_latitude  \\\n",
       "163  26e476f93a7b248da90b883b8d45f3ff   1.812810e+11        39.816110   \n",
       "185  a7cf5b5a11e2586b6deb168d71c763ef   6.339301e+10        36.700132   \n",
       "\n",
       "     school_longitude   school_city school_state  school_zip school_metro  \\\n",
       "163        -86.283113  Indianapolis           IN     46214.0        urban   \n",
       "185       -121.657760       Salinas           CA     93906.0        urban   \n",
       "\n",
       "                    school_district school_county school_charter  \\\n",
       "163                Msd Of Wayne Twp        Marion          False   \n",
       "185  Salinas City Elem Sch District      Monterey          False   \n",
       "\n",
       "    school_magnet school_year_round school_nlns school_kipp  \\\n",
       "163         False             False       False       False   \n",
       "185         False             False       False       False   \n",
       "\n",
       "    school_charter_ready_promise teacher_prefix teacher_teach_for_america  \\\n",
       "163                        False           Mrs.                     False   \n",
       "185                        False            Ms.                     False   \n",
       "\n",
       "    primary_focus_subject   primary_focus_area secondary_focus_subject  \\\n",
       "163              Literacy  Literacy & Language                     NaN   \n",
       "185           Mathematics       Math & Science                Literacy   \n",
       "\n",
       "    secondary_focus_area resource_type poverty_level    grade_level  \\\n",
       "163                  NaN         Books          high  Grades PreK-2   \n",
       "185  Literacy & Language      Supplies          high  Grades PreK-2   \n",
       "\n",
       "     vendor_shipping_charges  sales_tax  payment_processing_charges  \\\n",
       "163                     0.00       0.00                       11.50   \n",
       "185                     3.84      35.14                        5.76   \n",
       "\n",
       "     fulfillment_labor_materials  total_price_excluding_optional_support  \\\n",
       "163                         35.0                                  813.50   \n",
       "185                         35.0                                  463.78   \n",
       "\n",
       "     total_price_including_optional_support  students_reached  \\\n",
       "163                                  957.06              24.0   \n",
       "185                                  545.62              23.0   \n",
       "\n",
       "     total_donations  num_donors eligible_double_your_impact_match  \\\n",
       "163              NaN           0                             False   \n",
       "185           523.92          20                              True   \n",
       "\n",
       "    eligible_almost_home_match funding_status date_posted date_completed  \\\n",
       "163                      False        expired  2011-04-29            NaN   \n",
       "185                      False      completed  2011-04-29     2011-04-30   \n",
       "\n",
       "    date_thank_you_packet_mailed date_expiration calendar_completed  \\\n",
       "163                          NaN      2011-09-28                NaN   \n",
       "185                          NaN      2011-09-28         2011-04-30   \n",
       "\n",
       "     year_completed calendar_expired  \n",
       "163               0       2011-09-28  \n",
       "185            2011       2011-09-28  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del old_df;del arch_data\n",
    "\n",
    "print(bigold.shape)\n",
    "\n",
    "bigold.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bigold['funding_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### insert data into database from Python (proof of concept - this won't be useful for big data, of course)\n",
    "#bigold.to_sql('hist_projects', engine, if_exists='replace',chunksize=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44789\n",
      "/home/russell/Documents/DataScience/DonorsChoose/Data/Metrics/pickle_0044788.pickle\n"
     ]
    }
   ],
   "source": [
    "#get all pickle files from folder into a list, 'picks'\n",
    "\n",
    "picks = sorted(glob.glob(\"/home/russell/Documents/DataScience/DonorsChoose/Data/Metrics/*pickle\")) \n",
    "\n",
    "print(len(picks))\n",
    "\n",
    "\n",
    "#this will create a master list with the same # of elements as projects\n",
    "basic_list = []\n",
    "\n",
    "for pf in picks:\n",
    "    #https://stackoverflow.com/a/3249684/1602288\n",
    "    stdout.write(\"\\r%s\" % pf)\n",
    "    stdout.flush()\n",
    "    check=pickle.load(open(pf,\"rb\"))\n",
    "    #check=check[['id','proposalURL']]\n",
    "    if (isinstance(check, pd.DataFrame)) and (len(check.index)>0):\n",
    "        basic_list.append(check)\n",
    "    #basic_list.append(check)\n",
    "    \n",
    "    \n",
    "    #basic_list.append(pickle.load(open(pf,\"rb\")))\n",
    "    #basic_list = basic_list+(pickle.load(open(picks[0],\"rb\")))\n",
    "    #sleep(.4)\n",
    "stdout.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1642201, 37)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigframe = pd.concat(basic_list)\n",
    "#schoolTypes, teacherTypes #these variables are 'dictionaries' and need to be dealt with\n",
    "\n",
    "bigframe=bigframe.drop(['schoolTypes', 'teacherTypes'], axis=1)\n",
    "\n",
    "bigframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/a/40121869/1602288\n",
    "ffd = bigframe['fullyFundedDate'].values.tolist()\n",
    "\n",
    "years=[]\n",
    "\n",
    "for date in ffd:\n",
    "    try:\n",
    "        years.append(parse(str(date), fuzzy=True).year)\n",
    "    except:   \n",
    "        years.append(np.nan)\n",
    "\n",
    "bigframe['ffyear']=years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nybig: 'latitude','longitude','ffyear'\n",
    "\n",
    "bigframe['latitude']=bigframe.latitude.astype(float)\n",
    "\n",
    "bigframe['longitude']=bigframe.longitude.astype(float)\n",
    "\n",
    "####replace nas for these two columns with 0, required for conversion to int\n",
    "values = {'ffyear':0,'numDonors':0}\n",
    "bigframe = bigframe.fillna(value=values)\n",
    "\n",
    "bigframe['ffyear']=bigframe.ffyear.astype(int)\n",
    "\n",
    "bigframe['numDonors']=bigframe.numDonors.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert data into database from Python\n",
    "\n",
    "bigframe.to_sql('scraped_project_metrics', engine, if_exists='append',chunksize=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect:\n",
    "con = None\n",
    "con = psycopg2.connect(database = dbname, user = username, host='localhost', password=pswd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"\"\"\n",
    "SELECT * FROM birth_data_table WHERE delivery_method='Cesarean';\n",
    "\"\"\"\n",
    "birth_data_from_sql = pd.read_sql_query(sql_query,con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### connect:\n",
    "con = None\n",
    "\n",
    "con = psycopg2.connect(database = dbname, user = username, host='localhost', password=pswd)\n",
    "\n",
    "### query:\n",
    "sql_query = \"\"\"\n",
    "SELECT * FROM hist_projects WHERE school_state='NY';\n",
    "\"\"\"\n",
    "\n",
    "old_NYdata_from_sql = pd.read_sql_query(sql_query,con)\n",
    "\n",
    "old_NYdata_from_sql.head(2)\n",
    "\n",
    "### Close communication with the database\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query:\n",
    "sql_query = \"\"\"\n",
    "SELECT * FROM birth_data_table WHERE delivery_method='Cesarean';\n",
    "\"\"\"\n",
    "birth_data_from_sql = pd.read_sql_query(sql_query,con)\n",
    "\n",
    "\n",
    "\n",
    "# Close communication with the database\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A='hist_projects'\n",
    "B='scraped_project_metrics'\n",
    "\n",
    "sql_query = \"\"\" SELECT * FROM hist_projects WHERE school_state='NY'; \"\"\"\n",
    "\n",
    "old_NYdata_from_sql = pd.read_sql_query(sql_query,con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', None)\n",
    "# pd.set_option('display.max_columns', 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nybig = bigframe[bigframe.state.eq('NY')]\n",
    "nybig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nybig.shape)\n",
    "print(nydf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nybig['expirationDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nydf['calendar_expired']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/a/41815118/1602288\n",
    "new_ny = pd.merge(nybig,nydf,left_on=['latitude','longitude','ffyear','numDonors','expirationDate'],right_on = ['school_latitude', 'school_longitude','year_completed','num_donors','calendar_expired'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ny.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(new_ny.loc[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigframe['expirationTime'] = bigframe['expirationTime'].apply(str)\n",
    "bigframe['expirationTime']=bigframe['expirationTime'].str[1:-5]\n",
    "bigframe['timeback']=pd.to_numeric(bigframe['expirationTime'])\n",
    "bigframe['right_date']=pd.to_datetime(bigframe['expirationDate'],format='%Y-%m-%d')\n",
    "bigframe['start_date'] = bigframe.apply(lambda row: row['right_date'] - timedelta(seconds=row['timeback']),axis = 1)\n",
    "\n",
    "#bigframe['right_date'] - timedelta(seconds=bigframe['timeback'])\n",
    "\n",
    "\n",
    "\n",
    "bigframe.head(3)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigframe['right_date']=pd.to_datetime(bigframe['expirationDate'],format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bigframe['right_date']=pd.to_datetime(bigframe['expirationDate'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_date = bigframe.expirationDate.values[0]\n",
    "type(exp_date)\n",
    "#right_date = date.fromisoformat(exp_date) #gets date into a datetime.date format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(bigframe['proposalURL'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(bigframe['expirationTime'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for colu in bigframe.columns:\n",
    "    print(bigframe[colu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 999)\n",
    "bigframe.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above line (to_sql) is doing a lot of heavy lifting. It's reading a dataframe, it's creating a table, and adding the data to the table. So ** SQLAlchemy is quite useful! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bigframe.shape)\n",
    "print(type(bigframe))\n",
    "print(bigframe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok = bigframe.loc[bigframe.astype(str).drop_duplicates().index]\n",
    "ok = bigframe.drop_duplicates(subset='id') #drop duplicate rows\n",
    "print(type(ok))\n",
    "print(ok.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = ok.drop_duplicates(subset=\"id\", keep=\"first\") #for some reason, some duplicate projs were kept, this drops'em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "#d.set_option(\"max_rows\", None) #undo by resetting --- pd.reset_option(“max_rows”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trailerdict = dict(zip(ok['id'],ok['fulfillmentTrailer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('/home/russell/Documents/DataScience/DonorsChoose/Data/trailers.pickle',\"wb\")\n",
    "pickle.dump(trailerdict, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donordict = dict(zip(ok['id'],ok['numDonors']))\n",
    "pickle_out = open('/home/russell/Documents/DataScience/DonorsChoose/Data/donor_num.pickle',\"wb\")\n",
    "pickle.dump(donordict, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trailers =ok['fulfillmentTrailer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"poster\", font_scale=1.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.distplot(ok[\"numDonors\"].dropna())\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bigframe['fulfillmentTrailer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigframe['id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_trailers = bigframe['fulfillmentTrailer'].array\n",
    "print(f_trailers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(what)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(what)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_a = what.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(w_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(10):\n",
    "    #print(b)\n",
    "    print(bigframe['fulfillmentTrailer'].array[b])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigframe['proposalURL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkdf = pd.DataFrame(project_IDs,columns =['proj_id'])\n",
    "checkdf\n",
    "pd.set_option(\"max_rows\", None) #undo by resetting --- pd.reset_option(“max_rows”)\n",
    "checkdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkdf['proj_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bewild = pd.DataFrame.from_dict(lookat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "#modified scrapy settings here:\n",
    "#/home/russell/anaconda3/envs/insight/lib/python3.8/site-packages/scrapy/settings\n",
    "#to include the user agents described here: https://www.scrapehero.com/how-to-fake-and-rotate-user-agents-using-python-3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/russell/Downloads/opendata_projects.csv\", thousands = ',')\n",
    "pd.set_option('display.max_columns', None)\n",
    "#pd.set_option(\"max_rows\", None) #undo by resetting --- pd.reset_option(“max_rows”)bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = \"https://www.donorschoose.org/common/json_feed.html?showFacetCounts=true&APIKey=H9v7hCeN&max=100&index=0\"\n",
    "historical = \"https://www.donorschoose.org/common/json_feed.html?showFacetCounts=true&APIKey=H9v7hCeN&max=40&historical=true&index=0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(historical)\n",
    "data_dict = json.loads(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_dict.items():\n",
    "    print (key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts_on_this_page = list(data_dict.values())\n",
    "\n",
    "proposal_ind = ([list(data_dict.keys()).index('proposals')])[0]  #\n",
    "\n",
    "proposal_list = dicts_on_this_page[proposal_ind]\n",
    "#dicts_on_this_page[proposal_ind]\n",
    "#proposal_ind = which(data.keys()=='proposals')\n",
    "#print(proposal_ind)\n",
    "#print(proposals_on_this_page[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_proposal = proposal_list[0] #returns dictionary of first proposal items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(first_proposal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in first_proposal.items():\n",
    "    print (key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _DRAW OUT SCREENS and FUNCTIONALITY GOALS FOR END OF WEEK_\n",
    "\n",
    "\n",
    "\n",
    "## MONDAY\n",
    "    Well scoped, clearly-defined problem + some data\n",
    "## \tTUESDAY\n",
    "    SQL[organized data] \n",
    "## \tWED \n",
    "    analytics/working algo/some results ----> (python linked to sql data)\n",
    "## \tTHUR – SQL mapped to PYTHON connected to FLASK (or something)\n",
    "\n",
    "\n",
    "# GOOD Qs to ASK SELF AND OTHERS\n",
    "#### \t-What’s actionable about your product?\n",
    "#### \t-Did you try other models?\n",
    "#### \t-Is this better than random?\n",
    "#### \t-Is this better than the simplest model?\n",
    "#### \t-Why did you choose these inputs?\n",
    "#### \t-How did you validate this?\n",
    "#### \t-What are your metrics for success?\n",
    "#### \t-What are the assumptions of your model?\n",
    "#### \t-How would you improve this project with more time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['primary_focus_area'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expired = df[(df['funding_status']=='expired')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['_teacher_acctid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
