{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from datetime import datetime, timedelta, date #for time duration calculations\n",
    "from dateutil.parser import parse #for fuzzy finding year\n",
    "\n",
    "import pickle #for saving output files, pickles\n",
    "from sys import stdout\n",
    "import time #for time.sleep function to delay calls\n",
    "from tqdm import tqdm #for updating loop\n",
    "#from os import listdir\n",
    "#from os.path import isfile, join\n",
    "import glob #pattern matching and expansion.\n",
    "\n",
    "## Python packages - you may have to pip install sqlalchemy, sqlalchemy_utils, and psycopg2.\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "from sqlalchemy.sql import table, column, select, update, insert\n",
    "import psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#In Python: Define your username and password used above. I've defined the database name (we're \n",
    "#using a dataset on births, so I call it birth_db). \n",
    "dbname = 'donors_db'\n",
    "username = 'xxxx'#username\n",
    "pswd = 'xxxx'#password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 'engine' is a connection to a database\n",
    "## Here, we're using postgres, but sqlalchemy can connect to other things too.\n",
    "engine = create_engine('postgresql://%s:%s@localhost/%s'%(username,pswd,dbname))\n",
    "print('postgresql://%s:%s@localhost/%s'%(username,pswd,dbname))\n",
    "print(engine.url)\n",
    "# Replace localhost with IP address if accessing a remote server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a database (if it doesn't exist)\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "print(database_exists(engine.url))\n",
    "print(engine.url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \n",
    "          \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "          \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "          \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "          \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect:\n",
    "con = None\n",
    "con = psycopg2.connect(database = dbname, user = username, host='localhost', password=pswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MERGE ARCHIVAL + SCRAPED DATA, CREATING NEW TABLE IN POSTGRESQL DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through states, merge from historical and scraped data\n",
    "#\n",
    "\n",
    "totalrows=0\n",
    "\n",
    "state_specific_obs={}\n",
    "\n",
    "for stateval in states:\n",
    "\n",
    "    ###########################################################\n",
    "    ### query: from historical data\n",
    "    hist_query = \"\"\"\n",
    "    SELECT * FROM hist_projects WHERE school_state='\"\"\"+stateval+\"';\\n\"\n",
    "\n",
    "\n",
    "    hist_state = pd.read_sql_query(hist_query,con)\n",
    "    orig_hist_rows = len(hist_state.index)\n",
    "    hist_state = hist_state.drop_duplicates(keep='first')\n",
    "    dedup_hist_rows = len(hist_state.index)\n",
    "\n",
    "    ############################################### \n",
    "    ### query: from scraped data\n",
    "    scrape_query = \"\"\"\n",
    "    SELECT * FROM scraped_project_metrics WHERE state='\"\"\"+stateval+\"';\\n\"\n",
    "\n",
    "    scrape_state = pd.read_sql_query(scrape_query,con)\n",
    "    orig_scrape_rows = len(scrape_state.index)\n",
    "    scrape_state = scrape_state.drop_duplicates(keep='first')\n",
    "    dedup_scrape_rows = len(scrape_state.index)\n",
    "    ###############################################################\n",
    "    print(\"For \"+stateval+\"\\nHistorical Raw Obs = \"+str(orig_hist_rows)+\"\\nDeDup Obs = \"+str(dedup_hist_rows))\n",
    "    print(\"Scraped Raw Obs = \"+str(orig_scrape_rows)+\"\\nDeDup Scraped Obs = \"+str(dedup_scrape_rows))\n",
    "\n",
    "    new_state = pd.merge(scrape_state,hist_state,left_on=['latitude','longitude','ffyear','numDonors','expirationDate'],right_on = ['school_latitude', 'school_longitude','year_completed','num_donors','calendar_expired'])\n",
    "    new_state = new_state.drop_duplicates(subset='id',keep='first')\n",
    "    merge_rows=len(new_state.index)\n",
    "    \n",
    "    state_specific_obs[stateval] = merge_rows\n",
    "    #state_specific_obs.update=({stateval:merge_rows})\n",
    "    \n",
    "    print(stateval+': total merge obs = '+str(merge_rows))\n",
    "    totalrows += merge_rows\n",
    "    \n",
    "    new_state.to_sql('merge_projects', engine, if_exists='append')\n",
    "print(\"Total merge obs = \"+str(totalrows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Close communication with the database\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# this will list objects in the working memory equivalent, sorted by size, descending\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
