{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:48:15.707346Z",
     "start_time": "2020-11-16T02:48:15.700556Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:48:16.126909Z",
     "start_time": "2020-11-16T02:48:16.123216Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle #for saving output files, pickles\n",
    "import time #for time.sleep function to delay calls\n",
    "from tqdm import tqdm #for updating loop\n",
    "#from os import listdir\n",
    "#from os.path import isfile, join\n",
    "import glob #pattern matching and expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:48:16.474695Z",
     "start_time": "2020-11-16T02:48:16.470154Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:48:17.342917Z",
     "start_time": "2020-11-16T02:48:17.328409Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import random\n",
    "from itertools import cycle\n",
    "import traceback\n",
    "\n",
    "user_agent_list = [\n",
    "   #Chrome\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 5.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',\n",
    "    #Firefox\n",
    "    'Mozilla/4.0 (compatible; MSIE 9.0; Windows NT 6.1)',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (Windows NT 6.2; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.0; Trident/5.0)',\n",
    "    'Mozilla/5.0 (Windows NT 6.3; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0)',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Win64; x64; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)',\n",
    "    'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; Trident/6.0)',\n",
    "    'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; .NET CLR 2.0.50727; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729)'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:48:17.988906Z",
     "start_time": "2020-11-16T02:48:17.965239Z"
    }
   },
   "outputs": [],
   "source": [
    "IP_start = pd.read_csv(\"/home/russell/Documents/DataScience/DonorsChoose/IPs/eighty_1.csv\",header=None)\n",
    "proxies = IP_start.iloc[:,0].values.tolist()\n",
    "random.shuffle(proxies)\n",
    "proxy_pool = cycle(proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:48:19.886265Z",
     "start_time": "2020-11-16T02:48:19.857724Z"
    }
   },
   "outputs": [],
   "source": [
    "def proposal_process(proplist,requestpath):\n",
    "    '''takes a list with proposal info and processes some info into a df '''\n",
    "    #we can use values in these keys 'as is'\n",
    "    keeperkeys = ['id', 'proposalURL', 'fundURL', 'imageURL', 'retinaImageURL', 'thumbImageURL', 'fulfillmentTrailer', 'percentFunded', 'numDonors', 'costToComplete', 'studentLed', 'numStudents', 'professionalDevelopment', 'distanceLearningProject', 'totalPrice', 'freeShipping', 'teacherId', 'teacherName', 'teacherTypes', 'schoolTypes', 'schoolName', 'schoolUrl', 'city', 'zip', 'state', 'stateFullName', 'latitude', 'longitude', 'expirationDate', 'expirationTime', 'fundingStatus', 'fullyFundedDate', 'waitingForCheckPayment', 'modifiedDate','shortDescription']\n",
    "    \n",
    "    #these require more finagling\n",
    "    moreprocess = ['matchingFund', 'gradeLevel', 'povertyType']\n",
    "    \n",
    "    combine=[]\n",
    "    \n",
    "    for prop in proplist:\n",
    "        new_dict = {k: prop[k] for k in keeperkeys if k in prop}\n",
    "        keepinfo = pd.DataFrame.from_dict(new_dict,orient='index').T\n",
    "        \n",
    "        if(not bool(prop['matchingFund'].get('matchingKey'))):\n",
    "            keepinfo['matchingfund'] = 'no'\n",
    "        else:\n",
    "            keepinfo['matchingfund'] = 'no'\n",
    "            \n",
    "        keepinfo['grade_level'] = prop['gradeLevel']['name']\n",
    "        keepinfo['poverty_level'] = prop['povertyType']['label']\n",
    "        combine.append(keepinfo)\n",
    "        \n",
    "    summarydf = pd.concat(combine)\n",
    "    summarydf['r_path']=requestpath*summarydf.shape[0]\n",
    "    return(summarydf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:48:21.730177Z",
     "start_time": "2020-11-16T02:48:21.713413Z"
    }
   },
   "outputs": [],
   "source": [
    "#baseurl = 'https://www.donorschoose.org/donors/search.html?historical=true&searchTag=-3' #funded, classroom projects only (no PD)\n",
    "baseurl = 'https://www.donorschoose.org/common/json_feed.html?showFacetCounts=true&APIKey=H9v7hCeN&max=50&historical=true&searchTag=-3'\n",
    "\n",
    "states = [\"\",\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \n",
    "          \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "          \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "          \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "          \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "addme = 'state='\n",
    "statelist = [addme + s for s in states]\n",
    "\n",
    "subjectlist = [\"\",'subject5=-5','subject5=32','subject5=16','subject5=21','subject5=18','subject5=17','subject5=19','subject5=20',\n",
    "               'subject2=-2','subject2=29','subject2=27','subject2=28','subject2=2',\n",
    "              'subject3=-3','subject3=13','subject3=14','subject3=9','subject3=15',\n",
    "               'subject4=-4','subject4=6','subject4=7','subject4=30','subject4=4','subject4=8',\n",
    "               'subject1=-1','subject1=12','subject1=1','subject1=11']\n",
    "                    # 'subject7=-7','subject8=-8'] #ignore #specialneeds(subject7),warmthcarehunger(subject8)\n",
    "#applied learning (subject5),health&sports (subject2), history&civics (subject3),literacy&lang(subject4),math&sci(subject1),\n",
    "\n",
    "\n",
    "showonlylist = ['','metroType=r','teacherNotFunded=true','moderateHighEconomicNeed=true','distanceLearning=only']\n",
    "#rural, teacher never funded before, high economic need, distance learning\n",
    "\n",
    "#No High School requests\n",
    "agegrouplist = ['','gradeType=1','gradeType=1&gradeLevel=-1','gradeType=1&gradeLevel=0','gradeType=1&gradeLevel=1','gradeType=1&gradeLevel=2',\n",
    "                'gradeType=2','gradeType=2&gradeLevel=3','gradeType=2&gradeLevel=4','gradeType=2&gradeLevel=5',\n",
    "                'gradeType=3','gradeType=3&gradeLevel=6','gradeType=3&gradeLevel=7','gradeType=3&gradeLevel=8',\n",
    "                'gradeType=4','gradeType=4&gradeLevel=9','gradeType=4&gradeLevel=10','gradeType=4&gradeLevel=11','gradeType=4&gradeLevel=12']\n",
    "\n",
    "#costlist = ['costToComplete=1','costToComplete=2',] #this has strange results for historical values\n",
    "\n",
    "#no filters by class of requests (e.g. art supplies)\n",
    "requestsforlist = ['']\n",
    "#                   'proposalType=16','proposalTypeCombo=Books','proposalType=10','proposalType=7',\n",
    "#                   'proposalType=15','proposalType=12','proposalType=18','proposalType=8',\n",
    "#                   'proposalType=11','proposalType=17','proposalType=13','proposalType=14']\n",
    "\n",
    "\n",
    "teacherfundedlist = ['','teacherNotFunded=true','teacherType=1'] #never funded teachers, TFA teachers\n",
    "schooltypelist =['']\n",
    "#schooltypelist = ['','schoolType=16','schoolType=1','schoolType=21','schoolType=5']#traditional, charter, head start, year-round\n",
    "#'schoolType=24', serving military"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T02:48:22.963385Z",
     "start_time": "2020-11-16T02:48:22.954145Z"
    }
   },
   "outputs": [],
   "source": [
    "baseurl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HERE, we will loop through the lists created above, creating all possible combinations of the sub-categories\n",
    "# EACH list has an empty element at the beginning, which we will handle in every loop\n",
    "# by effectively leaving that category BLANK (i.e. not using that filter)\n",
    "# AT THE END, we will add every new address to 'searchurls' (which we will then shuffle)\n",
    "\n",
    "\n",
    "####NOTE----this code CAN use a lot of memory and generate >40 million combinations IF ALL lists above are 'full'\n",
    "#          (often causing a crash if many other processes are running)\n",
    "\n",
    "\n",
    "search_urls =[]\n",
    "#search_urls will be a large list of web addresses enabling us to pull project info based on combinations \n",
    "# of filters (e.g. state, subject, student age, etc)\n",
    "#\n",
    "\n",
    "\n",
    "#loop through every state\n",
    "for state in statelist:\n",
    "    if state == '':\n",
    "        combo_url = baseurl\n",
    "    else:\n",
    "        combo_url = baseurl+'&'+state\n",
    "        \n",
    "    for subject in subjectlist:\n",
    "        if subject == '':\n",
    "            new_combo_url = combo_url\n",
    "        else:\n",
    "            new_combo_url = combo_url+'&'+subject\n",
    "            \n",
    "        for showme in showonlylist:\n",
    "            if showme == '':\n",
    "                double_new_url = new_combo_url\n",
    "            else:\n",
    "                double_new_url = new_combo_url+'&'+showme\n",
    "                \n",
    "            for agegroup in agegrouplist:\n",
    "                if agegroup == '':\n",
    "                    triple_new_url = double_new_url\n",
    "                else:\n",
    "                    triple_new_url = double_new_url+'&'+agegroup\n",
    "                    \n",
    "                for reQuest in requestsforlist:\n",
    "                    if reQuest == '':\n",
    "                        quad_new_url = triple_new_url\n",
    "                    else:\n",
    "                        quad_new_url = triple_new_url+'&'+reQuest\n",
    "                    \n",
    "                    for tf in teacherfundedlist:\n",
    "                        if tf == '':\n",
    "                            quint_new_url = quad_new_url\n",
    "                        else:\n",
    "                            quint_new_url = quad_new_url+'&'+tf\n",
    "                            \n",
    "                        for schType in schooltypelist:\n",
    "                            if schType == '':\n",
    "                                sext_new_url = quint_new_url\n",
    "                            else:\n",
    "                                sext_new_url = quint_new_url+'&'+schType\n",
    "                                \n",
    "                            search_urls.append(sext_new_url)\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create random list (len = 10) from search_urls to test rest of code before implementing on full list\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "tenrandos=[]\n",
    "\n",
    "for x in range(10):\n",
    "    #print(search_urls[x])\n",
    "    #print(random.choice(search_urls))\n",
    "    tenrandos.append(random.choice(search_urls))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(search_urls) #shuffles *search_urls* so calls are bouncing around randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_urls.index(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save complete, shuffled list of search_urls\n",
    "# pickle_out = open('/home/russell/Documents/DataScience/DonorsChoose/Data/search_urls.pickle',\"wb\")\n",
    "# pickle.dump(search_urls, pickle_out)\n",
    "# pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate through html addresses accessing DonorsChoose API to pull project info\n",
    "\n",
    "prog_count = 0\n",
    "iteration = 0\n",
    "out_file = \"/home/russell/Documents/DataScience/DonorsChoose/Data/Metrics/pickle_\"\n",
    "\n",
    "#first scraping eff\n",
    "\n",
    "#for x in tenrandos:   #testcase\n",
    "for x in search_urls:  #loop over all urls in [search_urls], which have been shuffled\n",
    "\n",
    "    page_to_use = x\n",
    "    \n",
    "    #Make the request\n",
    "    try:\n",
    "        r = requests.get(page_to_use) #send request to specific html address\n",
    "    except:\n",
    "        #tenner.append(random_element_from_tenner)#re-attaches item pulled off, to try again later\n",
    "        continue #if we have an exception, *continue* will skip the rest of the iteration\n",
    "    \n",
    "    try:\n",
    "        data_dict = json.loads(r.text) #load the text as a dictionary\n",
    "    except: #catch *all* exceptions\n",
    "        #tenner.append(random_element_from_tenner)#re-attaches item pulled off, to try again later\n",
    "        continue #if we have an exception, *continue* will skip the rest of the iteration\n",
    "    \n",
    "    dicts_on_this_page = list(data_dict.values())\n",
    "    proposal_ind = ([list(data_dict.keys()).index('proposals')])[0]  #\n",
    "    proposal_list = dicts_on_this_page[proposal_ind]\n",
    "\n",
    "    #if projects are returned with these criteria, len(proposal_list) will be > 0\n",
    "    if len(proposal_list)>0:\n",
    "        \n",
    "            outframe = proposal_process(proposal_list,page_to_use)\n",
    "            #print(outframe['teacherName'])\n",
    "            pickle_out = open(out_file+(\"{0:07}\".format(iteration))+'.pickle',\"wb\")\n",
    "            pickle.dump(outframe, pickle_out)\n",
    "            pickle_out.close()\n",
    "            iteration += 1\n",
    "            prog_count += 50\n",
    "            more_to_get = True\n",
    "            indexup = 0\n",
    "            \n",
    "            while more_to_get:\n",
    "                indexup +=50\n",
    "                new_page_to_use = page_to_use+'&index='+str(indexup)\n",
    "                try:\n",
    "                    r = requests.get(new_page_to_use) #send request to specific html address\n",
    "                except:\n",
    "                    #tenner.append(random_element_from_tenner)#re-attaches item pulled off, to try again later\n",
    "                    more_to_get = False\n",
    "                    continue #if we have an exception, *continue* will skip the rest of the iteration\n",
    "\n",
    "                try:\n",
    "                    data_dict = json.loads(r.text) #load the text as a dictionary\n",
    "                except: #catch *all* exceptions\n",
    "                    #tenner.append(random_element_from_tenner)#re-attaches item pulled off, to try again later\n",
    "                    more_to_get = False\n",
    "                    continue #if we have an exception, *continue* will skip the rest of the iteration\n",
    "                \n",
    "                dicts_on_this_page = list(data_dict.values())\n",
    "                proposal_ind = ([list(data_dict.keys()).index('proposals')])[0]  #\n",
    "                proposal_list = dicts_on_this_page[proposal_ind]\n",
    "\n",
    "                #if projects are returned with these criteria, len(proposal_list) will be > 0\n",
    "                if len(proposal_list)>0:\n",
    "                    outframe = proposal_process(proposal_list,page_to_use)\n",
    "                    #print(outframe['teacherName'])\n",
    "                    pickle_out = open(out_file+(\"{0:07}\".format(iteration))+'.pickle',\"wb\")\n",
    "                    pickle.dump(outframe, pickle_out)\n",
    "                    pickle_out.close()\n",
    "                    iteration += 1\n",
    "                    prog_count += 50\n",
    "                else:\n",
    "                    more_to_get = False\n",
    "                \n",
    "    #print(\"Current progress:\",np.round(iteration/(len(tenrandos))),\"%\")\n",
    "    time.sleep(np.random.rand()*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
