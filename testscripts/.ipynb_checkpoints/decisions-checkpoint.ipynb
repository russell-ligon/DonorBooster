{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import datetime\n",
    "from datetime import timedelta, date #for time duration calculations\n",
    "from dateutil.parser import parse #for fuzzy finding year\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pickle #for saving output files, pickles\n",
    "from sys import stdout\n",
    "import time #for time.sleep function to delay calls\n",
    "from tqdm import tqdm #for updating loop\n",
    "#from os import listdir\n",
    "#from os.path import isfile, join\n",
    "import glob #pattern matching and expansion.\n",
    "\n",
    "## Python packages - you may have to pip install sqlalchemy, sqlalchemy_utils, and psycopg2.\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "from sqlalchemy.sql import table, column, select, update, insert\n",
    "import psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#In Python: Define your username and password used above. I've defined the database name (we're \n",
    "#using a dataset on births, so I call it birth_db). \n",
    "dbname = 'donors_db'\n",
    "username = 'russell'\n",
    "pswd = 'bradypodion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = (\n",
    "    ('weeks', 604800),  # 60 * 60 * 24 * 7\n",
    "    ('days', 86400),    # 60 * 60 * 24\n",
    "    ('hours', 3600),    # 60 * 60\n",
    "    ('minutes', 60),\n",
    "    ('seconds', 1),\n",
    "    )\n",
    "\n",
    "def display_time(seconds, granularity=2):\n",
    "    result = []\n",
    "\n",
    "    for name, count in intervals:\n",
    "        value = seconds // count\n",
    "        if value:\n",
    "            seconds -= value * count\n",
    "            if value == 1:\n",
    "                name = name.rstrip('s')\n",
    "            result.append(\"{} {}\".format(value, name))\n",
    "    return ', '.join(result[:granularity])\n",
    "\n",
    "# Function convert seconds into day.decimal  \n",
    "def ConvertSectoDay(n): \n",
    "    day = n // (24 * 3600) \n",
    "    #print(day) #keep day\n",
    "    n = n % (24 * 3600) \n",
    "    daydec=(n/86400) # add this to day\n",
    "    addem=day+daydec\n",
    "    #https://stackoverflow.com/a/48812729/1602288\n",
    "    holder='{:g}'.format(float('{:.{p}g}'.format(addem, p=5)))\n",
    "    return(float(holder))\n",
    "\n",
    "def elapsedseconds(posted, completed, expiration):\n",
    "    formatuse = '%Y-%m-%d %H:%M:%S' # The format: see down this page:https://docs.python.org/3/library/datetime.html\n",
    "    otherformat = '%Y-%m-%d'\n",
    "    \n",
    "    #failed projects were never completed, so in those cases, use the expiration date\n",
    "    # if variable is None:\n",
    "    if completed is None:\n",
    "        try:\n",
    "            clock = datetime.datetime.strptime(expiration,formatuse) \n",
    "        except:\n",
    "            try:\n",
    "                clock = datetime.datetime.strptime(expiration,otherformat)\n",
    "            except:\n",
    "                clock = 'stop'\n",
    "    else:\n",
    "        try:\n",
    "            clock = datetime.datetime.strptime(completed,formatuse) \n",
    "        except:\n",
    "            try:\n",
    "                clock = datetime.datetime.strptime(completed,otherformat) \n",
    "            except:\n",
    "                clock = 'stop'\n",
    "            \n",
    "    if clock != 'stop': \n",
    "        try:\n",
    "            startclock = datetime.datetime.strptime(posted,formatuse)\n",
    "        except:\n",
    "            startclock = datetime.datetime.strptime(posted,otherformat)\n",
    "\n",
    "        elapsed = (clock-startclock).total_seconds()\n",
    "        \n",
    "    else:\n",
    "        elapsed = 123456789\n",
    "    return(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://russell:bradypodion@localhost/donors_db\n",
      "postgresql://russell:bradypodion@localhost/donors_db\n"
     ]
    }
   ],
   "source": [
    "## 'engine' is a connection to a database\n",
    "## Here, we're using postgres, but sqlalchemy can connect to other things too.\n",
    "engine = create_engine('postgresql://%s:%s@localhost/%s'%(username,pswd,dbname))\n",
    "print('postgresql://%s:%s@localhost/%s'%(username,pswd,dbname))\n",
    "print(engine.url)\n",
    "# Replace localhost with IP address if accessing a remote server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "postgresql://russell:bradypodion@localhost/donors_db\n"
     ]
    }
   ],
   "source": [
    "## create a database (if it doesn't exist)\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "print(database_exists(engine.url))\n",
    "print(engine.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect:\n",
    "con = None\n",
    "con = psycopg2.connect(database = dbname, user = username, host='localhost', password=pswd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical Raw Obs = 1425169\n",
      "DeDup Obs = 1425169\n"
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "### query: from historical data\n",
    "hist_query = \"\"\"\n",
    "SELECT * FROM hist_projects;\\n\"\"\"\n",
    "\n",
    "\n",
    "hist_state = pd.read_sql_query(hist_query,con)\n",
    "orig_hist_rows = len(hist_state.index)\n",
    "hist_state = hist_state.drop_duplicates(keep='first')\n",
    "dedup_hist_rows = len(hist_state.index)\n",
    "\n",
    "print(\"Historical Raw Obs = \"+str(orig_hist_rows)+\"\\nDeDup Obs = \"+str(dedup_hist_rows))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Close communication with the database\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# previous EDA suggests these are all abberant classes with less than 100 values\n",
    "hist_state=hist_state[hist_state.school_state != 'La']\n",
    "hist_state=hist_state[hist_state.teacher_prefix != 'Mr. & Mrs.']\n",
    "hist_state=hist_state[hist_state.teacher_prefix != 'Mr. & Mrs. ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_state['latency_to_funded'] = hist_state.apply(lambda row: elapsedseconds(row['date_posted'],row['date_completed'],row['date_expiration']),axis=1)\n",
    "# if the latency was non-addressable, the returned value = 123456789, so now we drop those\n",
    "hist_state = hist_state[hist_state.latency_to_funded != 123456789]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_state['days_to_funding'] = hist_state.apply(lambda row: ConvertSectoDay(row.latency_to_funded),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_state['succeed']= np.where(hist_state['funding_status']=='completed', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace 'f' and 't' with 'true' and 'false' for these columns\n",
    "#https://stackoverflow.com/a/34697070/1602288\n",
    "\n",
    "hist_state[['school_charter','school_magnet','school_year_round','school_nlns','school_kipp',\n",
    "            'school_charter_ready_promise','teacher_teach_for_america','eligible_double_your_impact_match','eligible_almost_home_match']]= hist_state[['school_charter','school_magnet','school_year_round','school_nlns','school_kipp',\n",
    "                             'school_charter_ready_promise','teacher_teach_for_america','eligible_double_your_impact_match','eligible_almost_home_match']].replace(['f','t'], ['false', 'true'])\n",
    "\n",
    "#make new columns for posting time info, from splitting posting date = date_posted\n",
    "hist_state[['posting_year','posting_month','posting_day']]=hist_state['date_posted'].str.split(\"-\",expand=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trimmed=hist_state[['school_state','school_metro','school_charter', 'school_magnet', \n",
    "#                     'school_year_round','teacher_prefix','teacher_teach_for_america', \n",
    "#                     'primary_focus_subject','resource_type', 'poverty_level', 'grade_level',\n",
    "#                     'total_price_excluding_optional_support','students_reached',\n",
    "#                     'posting_month','days_to_funding']]\n",
    "\n",
    "trimmed=hist_state[['total_price_excluding_optional_support','students_reached',\n",
    "                    'posting_month','days_to_funding','succeed']]\n",
    "\n",
    "trimmed = trimmed[trimmed.days_to_funding < 150]\n",
    "trimmed = trimmed.dropna()\n",
    "trimmed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trimmed.astype({'posting_month':'int32'}).dtypes #cast posting month as integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funded_x=trimmed[trimmed['succeed']==1]\n",
    "notfund_y=trimmed[trimmed['succeed']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funded_x=funded_x['days_to_funding']\n",
    "notfund_y=notfund_y['days_to_funding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"poster\", font_scale=.6)\n",
    "\n",
    "bins = np.linspace(0, 150, 100)\n",
    "plt.hist(funded_x, bins, alpha=0.25, label='Funded')\n",
    "plt.hist(notfund_y, bins, alpha=0.5, label='NOT funded')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "\n",
    "plt.xlabel(\"Project duration\");\n",
    "plt.ylabel(\"Count\");\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"poster\", font_scale=1.3)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.distplot(trimmed[\"days_to_funding\"].dropna())\n",
    "ax.set_xlim(1,150)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary output = is a project funded or not?\n",
    "y = trimmed.succeed\n",
    "\n",
    "#\n",
    "x = trimmed.drop(['succeed'], axis=1)\n",
    "x_scaled = preprocessing.scale(x)\n",
    "# create training and testing vars\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.25)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a model\n",
    "logistic_regression = LogisticRegression()\n",
    "model = logistic_regression.fit(x_train, y_train)\n",
    "predictions = logistic_regression.predict(x_test)\n",
    "\n",
    "print(\"Score:\", model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logistic_regression.predict(x_test)\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "accuracy_percentage = 100 * accuracy\n",
    "accuracy_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use score method to get accuracy of model\n",
    "score = model.score(x_test, y_test)\n",
    "print(score)\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 22})\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'magma');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score: {0}'.format(score)\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "# font = {'family' : 'normal',\n",
    "#         'weight' : 'bold',\n",
    "#         'size'   : 30}\n",
    "\n",
    "# matplotlib.rc('font', **font)\n",
    "matplotlib.rcParams.update({'font.size': 42})\n",
    "\n",
    "logit_roc_auc = roc_auc_score(y_test, logistic_regression.predict(x_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logistic_regression.predict_proba(x_test)[:,1])\n",
    "plt.figure(figsize=(9, 9))\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc,linewidth=4)\n",
    "plt.plot([0, 1], [0, 1],'r--',linewidth=4)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.columns)\n",
    "print(logistic_regression.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=logistic_regression\n",
    "\n",
    "feature_importance = abs(clf.coef_[0])\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 42})\n",
    "plt.figure(figsize=(24, 16))\n",
    "featfig = plt.figure()\n",
    "featax = featfig.add_subplot(1, 1, 1)\n",
    "featax.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "featax.set_yticks(pos)\n",
    "featax.set_yticklabels(np.array(x.columns)[sorted_idx], fontsize=18)\n",
    "featax.set_xlabel('Relative Feature Importance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function convert months to school-year-months\n",
    "def ConvertGregorian_to_School(m): \n",
    "    m=int(m)\n",
    "    if m>=7:\n",
    "        sm=m-6\n",
    "    else:\n",
    "        sm=m+6\n",
    "\n",
    "    return(int(sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed['posting_month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed['posting_month'] = trimmed.apply(lambda row: ConvertGregorian_to_School(row.posting_month),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary output = is a project funded or not?\n",
    "y = trimmed.succeed\n",
    "\n",
    "#\n",
    "x = trimmed.drop(['succeed'], axis=1)\n",
    "x_scaled = preprocessing.scale(x)\n",
    "# create training and testing vars\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.25)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a model\n",
    "logistic_regression = LogisticRegression()\n",
    "model = logistic_regression.fit(x_train, y_train)\n",
    "predictions = logistic_regression.predict(x_test)\n",
    "\n",
    "print(\"Score:\", model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use score method to get accuracy of model\n",
    "score = model.score(x_test, y_test)\n",
    "print(score)\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 22})\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'magma');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score: {0}'.format(score)\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_roc_auc = roc_auc_score(y_test, logistic_regression.predict(x_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logistic_regression.predict_proba(x_test)[:,1])\n",
    "plt.figure(figsize=(9, 9))\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc,linewidth=4)\n",
    "plt.plot([0, 1], [0, 1],'r--',linewidth=4)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=logistic_regression\n",
    "\n",
    "feature_importance = abs(clf.coef_[0])\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 42})\n",
    "plt.figure(figsize=(24, 16))\n",
    "featfig = plt.figure()\n",
    "featax = featfig.add_subplot(1, 1, 1)\n",
    "featax.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "featax.set_yticks(pos)\n",
    "featax.set_yticklabels(np.array(x.columns)[sorted_idx], fontsize=18)\n",
    "featax.set_xlabel('Relative Feature Importance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical features\n",
    "features = pd.get_dummies(trimmed)\n",
    "print(features.shape)\n",
    "features = features.dropna()\n",
    "print(features.shape)\n",
    "\n",
    "features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary output = is a project funded or not?\n",
    "y = features.succeed\n",
    "\n",
    "#\n",
    "x = features.drop(['succeed'], axis=1)\n",
    "x_scaled = preprocessing.scale(x)\n",
    "# create training and testing vars\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.25)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a model\n",
    "logistic_regression = LogisticRegression()\n",
    "model = logistic_regression.fit(x_train, y_train)\n",
    "predictions = logistic_regression.predict(x_test)\n",
    "\n",
    "print(\"Score:\", model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_failed= len(features[features['succeed']==0])\n",
    "count_funded = len(features[features['succeed']==1])\n",
    "pct_of_fail = count_failed/(count_failed+count_funded)\n",
    "print(\"percentage of failed projects is \", pct_of_fail*100)\n",
    "pct_of_fund = count_funded/(count_failed+count_funded)\n",
    "print(\"percentage of funded projects is \", pct_of_fund*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed.groupby('grade_level').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed.groupby('poverty_level').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed.groupby('resource_type').mean()#resource_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use numpy to convert to arrays\n",
    "import numpy as np\n",
    "\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(features['succeed'])\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= features.drop('succeed', axis = 1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25,\n",
    "                                                                           random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate model \n",
    "rf = RandomForestRegressor(n_estimators= 1000, random_state=42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
